{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17090,"status":"ok","timestamp":1756969626055,"user":{"displayName":"sr c","userId":"02365314278665536029"},"user_tz":-540},"id":"RPJ-VYz-S9fZ","outputId":"a33666c4-07b0-4dd4-c084-bfcba6bc501a","collapsed":true},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (11.3.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (2.32.4)\n","Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (1.101.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n","Collecting ultralytics\n","  Downloading ultralytics-8.3.192-py3-none-any.whl.metadata (37 kB)\n","Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.23.0+cu126)\n","Requirement already satisfied: torchaudio in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n","Collecting boto3\n","  Downloading boto3-1.40.23-py3-none-any.whl.metadata (6.7 kB)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests) (3.4.3)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests) (2025.8.3)\n","Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai) (4.10.0)\n","Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai) (1.9.0)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.28.1)\n","Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.10.0)\n","Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from openai) (2.11.7)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai) (1.3.1)\n","Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.12/dist-packages (from openai) (4.15.0)\n","Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.0.2)\n","Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (3.10.0)\n","Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (4.12.0.88)\n","Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (6.0.2)\n","Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.16.1)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from ultralytics) (5.9.5)\n","Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.12/dist-packages (from ultralytics) (9.0.0)\n","Requirement already satisfied: polars in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.25.2)\n","Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n","  Downloading ultralytics_thop-2.0.17-py3-none-any.whl.metadata (14 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.19.1)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n","Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n","Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n","Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n","Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n","Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n","Collecting botocore<1.41.0,>=1.40.23 (from boto3)\n","  Downloading botocore-1.40.23-py3-none-any.whl.metadata (5.7 kB)\n","Collecting jmespath<2.0.0,>=0.7.1 (from boto3)\n","  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n","Collecting s3transfer<0.14.0,>=0.13.0 (from boto3)\n","  Downloading s3transfer-0.13.1-py3-none-any.whl.metadata (1.7 kB)\n","Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.12/dist-packages (from botocore<1.41.0,>=1.40.23->boto3) (2.9.0.post0)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n","Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.3)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.59.1)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.9)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (25.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.3)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n","Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.41.0,>=1.40.23->boto3) (1.17.0)\n","Downloading ultralytics-8.3.192-py3-none-any.whl (1.1 MB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading boto3-1.40.23-py3-none-any.whl (139 kB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m139.3/139.3 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading botocore-1.40.23-py3-none-any.whl (14.0 MB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m14.0/14.0 MB\u001b[0m \u001b[31m90.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n","Downloading s3transfer-0.13.1-py3-none-any.whl (85 kB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m85.3/85.3 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading ultralytics_thop-2.0.17-py3-none-any.whl (28 kB)\n","Installing collected packages: jmespath, botocore, s3transfer, ultralytics-thop, boto3, ultralytics\n","Successfully installed boto3-1.40.23 botocore-1.40.23 jmespath-1.0.1 s3transfer-0.13.1 ultralytics-8.3.192 ultralytics-thop-2.0.17\n"]}],"source":["!pip install pillow requests openai tqdm ultralytics torch torchvision torchaudio boto3"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":4036,"status":"ok","timestamp":1756970301716,"user":{"displayName":"sr c","userId":"02365314278665536029"},"user_tz":-540},"id":"L9ixJrDQbmTH"},"outputs":[],"source":["import os\n","from google.colab import userdata\n","\n","os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OPENAI_API_KEY_PJ\")\n","os.environ[\"AWS_S3_BUCKET_NAME\"] = userdata.get(\"AWS_S3_BUCKET_NAME\")\n","os.environ[\"AWS_ACCESS_KEY_ID\"] = userdata.get(\"AWS_ACCESS_KEY_ID\")\n","os.environ[\"AWS_SECRET_ACCESS_KEY\"] = userdata.get(\"AWS_SECRET_ACCESS_KEY\")\n","os.environ[\"AWS_REGION\"] = \"ap-northeast-2\"\n","os.environ[\"S3_FOLDER_PREFIX\"] = \"model_img\""]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hWoC-OhfW47W","executionInfo":{"status":"ok","timestamp":1756970428094,"user_tz":-540,"elapsed":55,"user":{"displayName":"sr c","userId":"02365314278665536029"}},"outputId":"a907a36b-81f9-402b-d114-c5f31b026709"},"outputs":[{"output_type":"stream","name":"stdout","text":["âœ… s3_uploader.py ëª¨ë“ˆì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.\n"]}],"source":["s3_uploader_code = '''\n","\"\"\"\n","s3_uploader.py\n","Virtual Try-on ê²°ê³¼ ì´ë¯¸ì§€ë¥¼ S3ì— ì—…ë¡œë“œí•˜ê³  URLì„ ë°˜í™˜í•˜ëŠ” ëª¨ë“ˆ\n","\"\"\"\n","\n","import os\n","import io\n","import boto3\n","from pathlib import Path\n","from typing import Optional, Union\n","from datetime import datetime\n","import uuid\n","from botocore.exceptions import ClientError, NoCredentialsError\n","\n","\n","class S3ImageUploader:\n","    \"\"\"S3ì— ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ê³  URLì„ ê´€ë¦¬í•˜ëŠ” í´ë˜ìŠ¤\"\"\"\n","\n","    def __init__(\n","        self,\n","        bucket_name: str,\n","        aws_access_key_id: Optional[str] = None,\n","        aws_secret_access_key: Optional[str] = None,\n","        region_name: str = 'ap-northeast-2',\n","        folder_prefix: str = 'tryon-images'\n","    ):\n","        \"\"\"S3 ì—…ë¡œë” ì´ˆê¸°í™”\"\"\"\n","        self.bucket_name = bucket_name\n","        self.folder_prefix = folder_prefix.strip('/')\n","\n","        try:\n","            if aws_access_key_id and aws_secret_access_key:\n","                self.s3_client = boto3.client(\n","                    's3',\n","                    aws_access_key_id=aws_access_key_id,\n","                    aws_secret_access_key=aws_secret_access_key,\n","                    region_name=region_name\n","                )\n","            else:\n","                self.s3_client = boto3.client('s3', region_name=region_name)\n","\n","            # ë²„í‚· ì ‘ê·¼ ê¶Œí•œ í™•ì¸\n","            self.s3_client.head_bucket(Bucket=bucket_name)\n","\n","        except NoCredentialsError:\n","            raise ValueError(\"AWS ìê²© ì¦ëª…ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n","        except ClientError as e:\n","            error_code = e.response['Error']['Code']\n","            if error_code == '403':\n","                raise ValueError(f\"S3 ë²„í‚· '{bucket_name}'ì— ëŒ€í•œ ì•¡ì„¸ìŠ¤ ê¶Œí•œì´ ì—†ìŠµë‹ˆë‹¤.\")\n","            elif error_code == '404':\n","                raise ValueError(f\"S3 ë²„í‚· '{bucket_name}'ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n","            else:\n","                raise ValueError(f\"S3 ì—°ê²° ì˜¤ë¥˜: {e}\")\n","\n","    def _generate_filename(self, product_id: str, extension: str = 'png') -> str:\n","        \"\"\"ê³ ìœ í•œ íŒŒì¼ëª… ìƒì„±\"\"\"\n","        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n","        unique_id = str(uuid.uuid4())[:8]\n","        return f\"{self.folder_prefix}/{timestamp}/{product_id}_{unique_id}.{extension}\"\n","\n","    def upload_file(self, file_path: Union[str, Path], product_id: str) -> str:\n","        \"\"\"\n","        ë¡œì»¬ íŒŒì¼ì„ S3ì— ì—…ë¡œë“œí•˜ê³  ê³µê°œ URL ë°˜í™˜\n","\n","        Args:\n","            file_path: ì—…ë¡œë“œí•  íŒŒì¼ ê²½ë¡œ\n","            product_id: ì œí’ˆ ID\n","\n","        Returns:\n","            S3 ê³µê°œ URL\n","        \"\"\"\n","        file_path = Path(file_path)\n","        if not file_path.exists():\n","            raise FileNotFoundError(f\"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_path}\")\n","\n","        extension = file_path.suffix.lstrip('.')\n","        s3_key = self._generate_filename(product_id, extension)\n","\n","        try:\n","            self.s3_client.upload_file(\n","                str(file_path),\n","                self.bucket_name,\n","                s3_key,\n","                ExtraArgs={\n","                    'ContentType': 'image/png' if extension.lower() == 'png' else 'image/jpeg',\n","                    'ACL': 'public-read'\n","                }\n","            )\n","\n","            return f\"https://{self.bucket_name}.s3.amazonaws.com/{s3_key}\"\n","\n","        except ClientError as e:\n","            raise RuntimeError(f\"S3 ì—…ë¡œë“œ ì‹¤íŒ¨: {e}\")\n","\n","\n","def setup_s3_uploader() -> S3ImageUploader:\n","    \"\"\"í™˜ê²½ë³€ìˆ˜ì—ì„œ ì„¤ì •ì„ ì½ì–´ S3 ì—…ë¡œë” ìƒì„±\"\"\"\n","    bucket_name = os.getenv('AWS_S3_BUCKET_NAME')\n","    if not bucket_name:\n","        raise ValueError(\"í™˜ê²½ë³€ìˆ˜ AWS_S3_BUCKET_NAMEì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")\n","\n","    return S3ImageUploader(\n","        bucket_name=bucket_name,\n","        aws_access_key_id=os.getenv('AWS_ACCESS_KEY_ID'),\n","        aws_secret_access_key=os.getenv('AWS_SECRET_ACCESS_KEY'),\n","        region_name=os.getenv('AWS_REGION', 'ap-northeast-2'),\n","        folder_prefix=os.getenv('S3_FOLDER_PREFIX', 'tryon-results')\n","    )\n","'''\n","\n","# íŒŒì¼ë¡œ ì €ì¥\n","with open('s3_uploader.py', 'w', encoding='utf-8') as f:\n","    f.write(s3_uploader_code)\n","\n","print(\"âœ… s3_uploader.py ëª¨ë“ˆì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n"]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6gqgm1f_W47W","executionInfo":{"status":"ok","timestamp":1756970645171,"user_tz":-540,"elapsed":419,"user":{"displayName":"sr c","userId":"02365314278665536029"}},"outputId":"3ec27621-5001-41b7-f346-34824e40d4f9"},"outputs":[{"output_type":"stream","name":"stdout","text":["âœ… S3 ì—…ë¡œë” ì´ˆê¸°í™” ì™„ë£Œ\n","   ë²„í‚·: elasticbeanstalk-ap-northeast-2-967883357924\n","   í´ë”: model_img\n"]}],"source":["import sys\n","import io, json, base64\n","from pathlib import Path\n","from typing import List, Dict, Any, Optional\n","import requests\n","from PIL import Image, ImageOps, ImageDraw, ImageChops\n","from openai import OpenAI\n","\n","# Python ê²½ë¡œì— í˜„ì¬ ë””ë ‰í† ë¦¬ ì¶”ê°€\n","if '.' not in sys.path:\n","    sys.path.append('.')\n","\n","# ê¸°ì¡´ ëª¨ë“ˆ ìºì‹œ ì‚­ì œ\n","if 's3_uploader' in sys.modules:\n","    del sys.modules['s3_uploader']\n","\n","# ========= ì‚¬ìš©ì ì„¤ì • =========\n","APP_JSON    = Path(\"app_product.json\")   # ì œí’ˆ ë¦¬ìŠ¤íŠ¸\n","OUT_DIR     = Path(\"out/tryon_openai\")\n","MODEL_NAME  = \"gpt-image-1\"              # OpenAI ì´ë¯¸ì§€ í¸ì§‘ ëª¨ë¸\n","\n","# ì´ë²ˆ ì‹¤í–‰ì—ì„œ ì²˜ë¦¬í•  idë“¤\n","SELECTED_IDS = [641]\n","\n","# ìº”ë²„ìŠ¤(ì¢Œ: ëª¨ë¸ / ìš°: ì˜ë¥˜ ì°¸ê³ )\n","SIZE      = (1536, 1024)   # (W, H)\n","LEFT_BOX  = (0, 0, 768, 1024)\n","RIGHT_BOX = (768, 0, 1536, 1024)\n","\n","# ì¹´í…Œê³ ë¦¬ë³„ ê¸°ë³¸ ë§ˆìŠ¤í¬ ë¹„ìœ¨(LEFT_BOX ê¸°ì¤€)\n","CATEGORY_MASK_RATIOS = {\n","    \"upper\":     (0.18, 0.18, 0.82, 0.64),\n","    \"lower\":     (0.22, 0.55, 0.78, 0.95),\n","    \"outer\":     (0.12, 0.12, 0.88, 0.85),\n","    \"onepiece\":  (0.18, 0.18, 0.82, 0.90),\n","    \"full\":      (0.10, 0.06, 0.90, 0.95),\n","}\n","MASK_FEATHER = 16\n","\n","# ë¡œì»¬ GPUë¡œ ìë™ ë§ˆìŠ¤í¬(ì„¸ê·¸ë©˜í…Œì´ì…˜+í¬ì¦ˆ) ì‚¬ìš©\n","USE_LOCAL_GPU_MASK = True\n","USE_POSE_LANDMARKS = True\n","YOLO_SEG_MODEL     = \"yolov8n-seg.pt\"\n","YOLO_POSE_MODEL    = \"yolov8n-pose.pt\"\n","MIN_CONF_KEYPT     = 0.35\n","\n","# S3 ì—…ë¡œë“œ ì„¤ì •\n","USE_S3_UPLOAD = True\n","\n","# OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”\n","client = OpenAI()\n","\n","# S3 ì—…ë¡œë” ì´ˆê¸°í™”\n","s3_uploader = None\n","if USE_S3_UPLOAD:\n","    try:\n","        from s3_uploader import setup_s3_uploader\n","        s3_uploader = setup_s3_uploader()\n","        print(f\"âœ… S3 ì—…ë¡œë” ì´ˆê¸°í™” ì™„ë£Œ\")\n","        print(f\"   ë²„í‚·: {s3_uploader.bucket_name}\")\n","        print(f\"   í´ë”: {s3_uploader.folder_prefix}\")\n","    except Exception as e:\n","        print(f\"âš ï¸ S3 ì—…ë¡œë” ì´ˆê¸°í™” ì‹¤íŒ¨: {e}\")\n","        USE_S3_UPLOAD = False"]},{"cell_type":"code","execution_count":26,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":65647,"status":"ok","timestamp":1756970859914,"user":{"displayName":"sr c","userId":"02365314278665536029"},"user_tz":-540},"id":"ROe66uDrMHyi","outputId":"e3e35b3e-426a-4bc1-ab16-91e6c8ed577c"},"outputs":[{"output_type":"stream","name":"stdout","text":["ğŸ’¾ ë¡œì»¬ ì €ì¥ ì™„ë£Œ: out/tryon_openai/641_tryon.png\n","ğŸ“¤ S3 ì—…ë¡œë“œ ì™„ë£Œ: https://elasticbeanstalk-ap-northeast-2-967883357924.s3.amazonaws.com/model_img/20250904_072739/641_3bfa1eb6.png\n","[OK] id=641 â†’ out/tryon_openai/641_tryon.png\n","\n","==================================================\n","ğŸ¯ Try-on ê²°ê³¼ ìš”ì•½\n","==================================================\n","âŒ S3 ì—…ë¡œë“œëœ ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤.\n","\n","==================================================\n"]}],"source":["# file: tryon_ids_openai.py\n","import os, io, json, base64\n","from pathlib import Path\n","from typing import List, Dict, Any, Optional\n","import requests\n","from PIL import Image, ImageOps, ImageDraw, ImageChops\n","from openai import OpenAI\n","from datetime import datetime\n","\n","def ensure_list(x):\n","    if x is None: return []\n","    return x if isinstance(x, list) else [x]\n","\n","def download_image(url: str) -> Image.Image:\n","    r = requests.get(url, timeout=60)\n","    r.raise_for_status()\n","    return Image.open(io.BytesIO(r.content)).convert(\"RGBA\")\n","\n","def download_bytes(url: str) -> bytes:\n","    r = requests.get(url, timeout=60)\n","    r.raise_for_status()\n","    return r.content\n","\n","def fit_into(img: Image.Image, box: tuple, keep_aspect=True, pad_color=(255,255,255,0)) -> Image.Image:\n","    x1,y1,x2,y2 = box\n","    w, h = x2-x1, y2-y1\n","    if keep_aspect:\n","        img = ImageOps.contain(img, (w,h))\n","        canvas = Image.new(\"RGBA\", (w,h), pad_color)\n","        canvas.paste(img, ((w - img.width)//2, (h - img.height)//2), img)\n","        return canvas\n","    return img.resize((w,h), Image.LANCZOS)\n","\n","def make_collage(model_img: Image.Image, garments: List[Image.Image]) -> Image.Image:\n","    W,H = SIZE\n","    canvas = Image.new(\"RGBA\", (W,H), (255,255,255,255))\n","    left_fitted = fit_into(model_img, LEFT_BOX)\n","    canvas.paste(left_fitted, (LEFT_BOX[0], LEFT_BOX[1]), left_fitted)\n","\n","    rows = max(1, min(2, len(garments)))\n","    each_h = (RIGHT_BOX[3] - RIGHT_BOX[1]) // rows\n","    for i, g in enumerate(garments[:rows], 0):\n","        slot = (RIGHT_BOX[0], RIGHT_BOX[1] + i*each_h, RIGHT_BOX[2], RIGHT_BOX[1] + (i+1)*each_h)\n","        fitted = fit_into(g, slot)\n","        canvas.paste(fitted, (slot[0], slot[1]), fitted)\n","    return canvas\n","\n","def _feather(mask: Image.Image, radius: int) -> Image.Image:\n","    if radius <= 0: return mask\n","    small = mask.resize((max(1,mask.width//4), max(1,mask.height//4)), Image.BILINEAR)\n","    return small.resize(mask.size, Image.BILINEAR)\n","\n","# =============================================================================\n","# 6. GPU ë§ˆìŠ¤í¬ ë° í¬ì¦ˆ ê´€ë ¨ í•¨ìˆ˜ë“¤\n","# =============================================================================\n","def _person_mask_yolov8(model_img_rgba: Image.Image) -> Optional[Image.Image]:\n","    try:\n","        from ultralytics import YOLO\n","        import torch\n","    except Exception:\n","        return None\n","    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","    model = YOLO(YOLO_SEG_MODEL)\n","    crop = model_img_rgba.crop(LEFT_BOX).convert(\"RGB\")\n","    results = model.predict(crop, imgsz=768, conf=0.25, device=device, verbose=False)\n","    if not results or len(results[0].masks or []) == 0:\n","        return None\n","    import numpy as np\n","    m = Image.new(\"L\", crop.size, 0)\n","    for j, cls in enumerate(results[0].boxes.cls.tolist()):\n","        if int(cls) == 0 and results[0].masks is not None:  # person class\n","            mask_arr = results[0].masks.data[j].cpu().numpy()\n","            mask_img = Image.fromarray((mask_arr*255).astype(\"uint8\"), mode=\"L\")\n","            m = ImageChops.lighter(m, mask_img)\n","    full = Image.new(\"L\", SIZE, 0)\n","    full.paste(m, (LEFT_BOX[0], LEFT_BOX[1]))\n","    return full\n","\n","def _pose_keypoints_yolo(model_img_rgba: Image.Image) -> Optional[dict]:\n","    try:\n","        from ultralytics import YOLO\n","        import torch, numpy as np\n","    except Exception:\n","        return None\n","    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","    crop = model_img_rgba.crop(LEFT_BOX).convert(\"RGB\")\n","    model = YOLO(YOLO_POSE_MODEL)\n","    res = model.predict(crop, imgsz=768, device=device, conf=0.25, verbose=False)\n","    if not res:\n","        return None\n","    r = res[0]\n","    if r.keypoints is None or r.boxes is None or len(r.keypoints) == 0:\n","        return None\n","\n","    areas = (r.boxes.xyxy[:,2]-r.boxes.xyxy[:,0]) * (r.boxes.xyxy[:,3]-r.boxes.xyxy[:,1])\n","    idx = int((areas).argmax())\n","    kpts = r.keypoints.xy[idx].cpu().numpy()  # (17,2)\n","    conf = r.keypoints.conf[idx].cpu().numpy() if r.keypoints.conf is not None else __import__(\"numpy\").ones((kpts.shape[0],))\n","\n","    KP = {\"L_SHOULDER\":5,\"R_SHOULDER\":6,\"L_HIP\":11,\"R_HIP\":12,\"L_KNEE\":13,\"R_KNEE\":14,\"L_ANKLE\":15,\"R_ANKLE\":16}\n","    def y_of(a,b):\n","        ys=[]\n","        for i in (a,b):\n","            if i < len(kpts) and conf[i] >= MIN_CONF_KEYPT: ys.append(kpts[i][1])\n","        return int(__import__(\"numpy\").mean(ys)) if ys else None\n","\n","    y_sh = y_of(KP[\"L_SHOULDER\"], KP[\"R_SHOULDER\"])\n","    y_hp = y_of(KP[\"L_HIP\"],      KP[\"R_HIP\"])\n","    y_kn = y_of(KP[\"L_KNEE\"],     KP[\"R_KNEE\"])\n","    y_an = y_of(KP[\"L_ANKLE\"],    KP[\"R_ANKLE\"])\n","\n","    x1,y1,x2,y2 = r.boxes.xyxy[idx].cpu().numpy().astype(int).tolist()\n","    x1 += LEFT_BOX[0]; x2 += LEFT_BOX[0]\n","    y1 += LEFT_BOX[1]; y2 += LEFT_BOX[1]\n","\n","    def to_full_y(y): return int(y + LEFT_BOX[1]) if y is not None else None\n","    return {\"shoulders_y\":to_full_y(y_sh),\"hips_y\":to_full_y(y_hp),\"knees_y\":to_full_y(y_kn),\"ankles_y\":to_full_y(y_an),\"bbox\":(x1,y1,x2,y2)}\n","\n","def make_mask(category: str, base_img: Image.Image) -> Image.Image:\n","    mask = Image.new(\"L\", SIZE, 0)\n","    draw = ImageDraw.Draw(mask)\n","\n","    dyn = _pose_keypoints_yolo(base_img) if USE_POSE_LANDMARKS else None\n","    def rect(x1,y1,x2,y2): draw.rectangle((int(x1),int(y1),int(x2),int(y2)), fill=255)\n","\n","    if dyn:\n","        x1,y1,x2,y2 = dyn[\"bbox\"]\n","        pad_x = int((x2-x1)*0.08); pad_y = int((y2-y1)*0.05)\n","        sh = dyn[\"shoulders_y\"] or (LEFT_BOX[1] + int((LEFT_BOX[3]-LEFT_BOX[1])*0.22))\n","        hp = dyn[\"hips_y\"]      or (LEFT_BOX[1] + int((LEFT_BOX[3]-LEFT_BOX[1])*0.58))\n","        kn = dyn[\"knees_y\"]     or (LEFT_BOX[1] + int((LEFT_BOX[3]-LEFT_BOX[1])*0.80))\n","        an = dyn[\"ankles_y\"]    or (LEFT_BOX[1] + int((LEFT_BOX[3]-LEFT_BOX[1])*0.95))\n","\n","        cat = (category or \"upper\").lower()\n","        if cat == \"upper\":\n","            rect(max(LEFT_BOX[0], x1+pad_x), max(LEFT_BOX[1], sh - (hp-sh)*0.2),\n","                 min(LEFT_BOX[2], x2-pad_x), min(LEFT_BOX[3], hp + (hp-sh)*0.05))\n","        elif cat == \"lower\":\n","            rect(max(LEFT_BOX[0], x1+pad_x), max(LEFT_BOX[1], hp - (hp-sh)*0.05),\n","                 min(LEFT_BOX[2], x2-pad_x), min(LEFT_BOX[3], an))\n","        elif cat == \"outer\":\n","            rect(max(LEFT_BOX[0], x1+int(pad_x*0.7)), max(LEFT_BOX[1], sh - (hp-sh)*0.6),\n","                 min(LEFT_BOX[2], x2-int(pad_x*0.7)), min(LEFT_BOX[3], kn))\n","        elif cat in (\"onepiece\",\"dress\"):\n","            rect(max(LEFT_BOX[0], x1+pad_x), max(LEFT_BOX[1], sh - (hp-sh)*0.2),\n","                 min(LEFT_BOX[2], x2-pad_x), min(LEFT_BOX[3], max(kn, hp + (hp-sh))))\n","        else:  # full\n","            rect(max(LEFT_BOX[0], x1+pad_x), max(LEFT_BOX[1], y1+pad_y),\n","                 min(LEFT_BOX[2], x2-pad_x), min(LEFT_BOX[3], an))\n","    else:\n","        rx1,ry1,rx2,ry2 = CATEGORY_MASK_RATIOS.get((category or \"upper\").lower(), CATEGORY_MASK_RATIOS[\"upper\"])\n","        lx1,ly1,lx2,ly2 = LEFT_BOX\n","        rect(lx1 + (lx2-lx1)*rx1, ly1 + (ly2-ly1)*ry1, lx1 + (lx2-lx1)*rx2, ly1 + (ly2-ly1)*ry2)\n","\n","    if USE_LOCAL_GPU_MASK:\n","        person = _person_mask_yolov8(base_img)\n","        if person is not None:\n","            mask = ImageChops.multiply(mask, person)\n","\n","    return _feather(mask, MASK_FEATHER)\n","\n","# =============================================================================\n","# 7. OpenAI ì´ë¯¸ì§€ í¸ì§‘ + S3 ì—…ë¡œë“œ í•¨ìˆ˜\n","# =============================================================================\n","def call_openai_edit(base_img, mask_img, prompt, out_path):\n","    \"\"\"OpenAI ì´ë¯¸ì§€ í¸ì§‘ + S3 ì—…ë¡œë“œ\"\"\"\n","    # 1) ë§ˆìŠ¤í¬ë¥¼ RGBAë¡œ ë§Œë“¤ê³ , ì•ŒíŒŒ ì±„ë„ì— ë§ˆìŠ¤í¬ë¥¼ ë³µì‚¬\n","    mask_L = mask_img.convert(\"L\")\n","    mask_rgba = mask_L.convert(\"RGBA\")\n","    mask_rgba.putalpha(mask_L)\n","\n","    # 2) BytesIOì— ì €ì¥ + name ë¶€ì—¬\n","    base_buf = io.BytesIO()\n","    base_img.save(base_buf, format=\"PNG\")\n","    base_buf.seek(0)\n","    base_buf.name = \"base.png\"\n","\n","    mask_buf = io.BytesIO()\n","    mask_rgba.save(mask_buf, format=\"PNG\")\n","    mask_buf.seek(0)\n","    mask_buf.name = \"mask.png\"\n","\n","    # 3) OpenAI API í˜¸ì¶œ\n","    resp = client.images.edit(\n","        model=MODEL_NAME,\n","        image=base_buf,\n","        mask=mask_buf,\n","        prompt=prompt,\n","        size=\"1024x1024\",\n","        n=1,\n","    )\n","\n","    # 4) ë¡œì»¬ ì €ì¥\n","    out_path.parent.mkdir(parents=True, exist_ok=True)\n","    b64 = resp.data[0].b64_json\n","    out_path.write_bytes(base64.b64decode(b64))\n","    print(f\"ğŸ’¾ ë¡œì»¬ ì €ì¥ ì™„ë£Œ: {out_path}\")\n","\n","    # 5) S3 ì—…ë¡œë“œ\n","    if USE_S3_UPLOAD and s3_uploader:\n","        try:\n","            product_id = out_path.stem.split('_')[0]\n","            s3_url = s3_uploader.upload_file(out_path, product_id)\n","            print(f\"ğŸ“¤ S3 ì—…ë¡œë“œ ì™„ë£Œ: {s3_url}\")\n","        except Exception as e:\n","            print(f\"âŒ S3 ì—…ë¡œë“œ ì‹¤íŒ¨: {e}\")\n","\n","    return str(out_path)\n","\n","\n","# =============================================================================\n","# 8. ëª¨ë¸ ë° ì œí’ˆ ë°ì´í„° ë¡œë”© í•¨ìˆ˜ë“¤\n","# =============================================================================\n","def load_models_by_gender(path: Path) -> dict:\n","    \"\"\"model_list.jsonì„ ë¡œë“œí•´ ì„±ë³„ë³„ ëŒ€í‘œ ì´ë¯¸ì§€ URL ë”•ì…”ë„ˆë¦¬ë¡œ ì •ê·œí™”\"\"\"\n","    if not path.exists():\n","        raise FileNotFoundError(f\"ëª¨ë¸ JSON ì—†ìŒ: {path}\")\n","\n","    raw = path.read_text(encoding=\"utf-8\").strip()\n","    try:\n","        obj = json.loads(raw)\n","    except json.JSONDecodeError:\n","        obj = [json.loads(l) for l in raw.splitlines() if l.strip()]\n","\n","    db = {}\n","\n","    def _norm_gender(g: str) -> str | None:\n","        g = (g or \"\").strip().lower()\n","        if g in (\"female\",\"f\",\"ì—¬\",\"ì—¬ì\",\"woman\",\"girl\",\"w\"): return \"female\"\n","        if g in (\"male\",\"m\",\"ë‚¨\",\"ë‚¨ì\",\"man\",\"boy\"):         return \"male\"\n","        if g in (\"default\",\"any\",\"*\"):                        return \"default\"\n","        return None\n","\n","    def _extract_url(v) -> str | None:\n","        if isinstance(v, dict):\n","            return v.get(\"model_url\") or v.get(\"image_url\")\n","        if isinstance(v, str):\n","            return v\n","        return None\n","\n","    if isinstance(obj, dict):\n","        for g, v in obj.items():\n","            key = _norm_gender(g)\n","            url = _extract_url(v)\n","            if key and url:\n","                db[key] = url\n","    else:\n","        for it in obj:\n","            key = _norm_gender(it.get(\"gender\"))\n","            url = it.get(\"model_url\") or it.get(\"image_url\")\n","            if key and url:\n","                db[key] = url\n","\n","    return db\n","\n","def resolve_model_url_by_gender(item: dict, models_by_gender: dict) -> Optional[str]:\n","    g = str(item.get(\"gender\") or item.get(\"model_gender\") or \"\").strip().lower()\n","    key = \"female\" if g in (\"female\",\"f\",\"ì—¬\",\"ì—¬ì\",\"woman\",\"girl\",\"w\") else \"male\" if g in (\"male\",\"m\",\"ë‚¨\",\"ë‚¨ì\",\"man\",\"boy\") else None\n","    if key and key in models_by_gender: return models_by_gender[key]\n","    if \"default\" in models_by_gender:   return models_by_gender[\"default\"]\n","    return models_by_gender.get(\"female\") or models_by_gender.get(\"male\")\n","\n","def load_items_by_ids(path: Path, selected_ids: List[Any]) -> List[dict]:\n","    raw = path.read_text(encoding=\"utf-8\")\n","    try:\n","        data = json.loads(raw)\n","        if isinstance(data, dict): data = [data]\n","    except json.JSONDecodeError:\n","        data = [json.loads(l) for l in raw.splitlines() if l.strip()]\n","    sids = {str(x) for x in (selected_ids or [])}\n","    picked = [it for it in data if str(it.get(\"id\") or it.get(\"external_id\")) in sids]\n","    if not picked:\n","        raise ValueError(f\"id {sorted(sids)} í•­ëª©ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.\")\n","    return picked\n","\n","# =============================================================================\n","# 9. ê²°ê³¼ í™•ì¸ í•¨ìˆ˜ë“¤\n","# =============================================================================\n","def get_s3_urls_from_results(results_dir=\"out/tryon_openai\"):\n","    \"\"\"ìƒì„±ëœ ê²°ê³¼ì—ì„œ S3 URLë“¤ì„ ìˆ˜ì§‘\"\"\"\n","    results_dir = Path(results_dir)\n","    s3_urls = {}\n","\n","    for info_file in results_dir.glob(\"*_info.json\"):\n","        try:\n","            data = json.loads(info_file.read_text())\n","            product_id = data.get(\"product_id\")\n","            s3_url = data.get(\"s3_url\")\n","\n","            if product_id and s3_url:\n","                s3_urls[product_id] = {\n","                    \"url\": s3_url,\n","                    \"folder\": data.get(\"s3_folder\"),\n","                    \"local_path\": data.get(\"local_path\"),\n","                    \"timestamp\": data.get(\"timestamp\")\n","                }\n","        except:\n","            continue\n","\n","    return s3_urls\n","\n","from PIL import Image\n","\n","def main():\n","    if not os.getenv(\"OPENAI_API_KEY\"):\n","        raise RuntimeError(\"í™˜ê²½ë³€ìˆ˜ OPENAI_API_KEY í•„ìš”\")\n","\n","    # GPU ë„êµ¬ í™•ì¸(ì—†ìœ¼ë©´ ìë™ ë¹„í™œì„±í™”)\n","    if USE_LOCAL_GPU_MASK or USE_POSE_LANDMARKS:\n","        try:\n","            import torch, ultralytics  # noqa\n","        except Exception as e:\n","            print(f\"[ê²½ê³ ] ë¡œì»¬ GPU ë§ˆìŠ¤í¬/í¬ì¦ˆ ë¹„í™œì„±í™”: {e}\")\n","            globals()[\"USE_LOCAL_GPU_MASK\"] = False\n","            globals()[\"USE_POSE_LANDMARKS\"] = False\n","\n","    # ì œí’ˆ ë°ì´í„° ë¡œë“œ (ì‹¤ì œ URLì€ ë¬´ì‹œ)\n","    items = load_items_by_ids(APP_JSON, SELECTED_IDS)\n","    OUT_DIR.mkdir(parents=True, exist_ok=True)\n","\n","    for item in items:\n","        pid = item.get(\"id\") or item.get(\"external_id\")\n","\n","        # ì‹¤ì œ garment_urls ë¬´ì‹œ â†’ ë”ë¯¸ ì´ë¯¸ì§€ 2ê°œ ìƒì„±\n","        garments = []\n","        for i, color in enumerate([\"red\", \"blue\"]):\n","            g = Image.new(\"RGBA\", (512, 512), color=color)\n","            garments.append(g)\n","\n","        # ëª¨ë¸ ì´ë¯¸ì§€ë„ ë”ë¯¸ ìƒì„± (ë…¹ìƒ‰)\n","        model_img = Image.new(\"RGBA\", (512, 1024), color=\"green\")\n","\n","        # ì½œë¼ì£¼ & ë§ˆìŠ¤í¬\n","        collage  = make_collage(model_img, garments)\n","        category = str(item.get(\"category\") or \"upper\").lower()\n","        mask_img = make_mask(category, collage)\n","\n","        # í”„ë¡¬í”„íŠ¸ (ë”ë¯¸)\n","        prompt = \"ì™¼ìª½ ì‚¬ëŒì— ë…¹ìƒ‰ ì˜·ì„ ì…íˆê³  ì˜¤ë¥¸ìª½ ì˜ë¥˜(ë¹¨ê°•, íŒŒë‘)ë¥¼ ì°¸ì¡°í•˜ì—¬ ì°©ì¥ì²˜ëŸ¼ ë³´ì´ê²Œ\"\n","\n","        # ìƒì„± â†’ ì´ë¯¸ì§€ íŒŒì¼ ì €ì¥ + S3 ì—…ë¡œë“œ\n","        out_path = OUT_DIR / f\"{pid}_tryon.png\"\n","        try:\n","            saved = call_openai_edit(collage, mask_img, prompt, out_path)\n","            print(f\"[OK] id={pid} â†’ {saved}\")\n","        except Exception as e:\n","            print(f\"[ERROR] id={pid} í¸ì§‘ ì‹¤íŒ¨: {e}\")\n","\n","\n","\n","# =============================================================================\n","# 11. ì‹¤í–‰\n","# =============================================================================\n","if __name__ == \"__main__\":\n","    main()\n"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.11"}},"nbformat":4,"nbformat_minor":0}